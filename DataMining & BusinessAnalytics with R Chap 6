## CHAPTER 6: PENALTY-BASED VARIABLE SELECTION IN REGRESSION
## MODELS WITH MANY PARAMETERS (LASSO)

## Example 1: Prostate Cancer 

prostate <- read.csv("prostate.csv")
prostate[1:3,]
m1=lm(lcavol~.,data=prostate)
summary(m1)

## the model.matrix statement defines the model to be fitted
x <- model.matrix(lcavol~age+lbph+lcp+gleason+lpsa,data=prostate)
x=x[,-1]


## stripping off the column of 1s as LASSO includes the intercept
## automatically
library(lars)


## lasso on all data
lasso <- lars(x=x,y=prostate$lcavol,trace=TRUE)

## trace of lasso (standardized) coefficients for varying penalty
plot(lasso)
lasso
coef(lasso,s=c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),mode="fraction")


## cross-validation using 10 folds
cv.lars(x=x,y=prostate$lcavol,K=10)


## another way to evaluate lassoâ€™s out-of-sample prediction performance
MSElasso25=dim(10)
MSElasso50=dim(10)
MSElasso75=dim(10)
MSElasso100=dim(10)
set.seed(1)
for(i in 1:10){
      train <- sample(1:nrow(prostate),80)
      lasso <- lars(x=x[train,],y=prostate$lcavol[train])
      MSElasso25[i]=
            mean((predict(lasso,x[-train,],s=.25,mode="fraction")$fitprostate$lcavol[-train])^2)
      
      MSElasso50[i]=
            mean((predict(lasso,x[-train,],s=.50,mode="fraction")$fitprostate$lcavol[-train])^2)
      
      MSElasso75[i]=
            mean((predict(lasso,x[-train,],s=.75,mode="fraction")$fitprostate$lcavol[-train])^2)
      
      MSElasso100[i]=
            mean((predict(lasso,x[-train,],s=1.00,mode="fraction")$fitprostate$lcavol[-train])^2)
      
}

mean(MSElasso25)
mean(MSElasso50)
mean(MSElasso75)
mean(MSElasso100) 

boxplot(MSElasso25,MSElasso50,MSElasso75,MSElasso100,ylab="MSE", sub="LASSO
model",xlab="s=0.25 s=0.50 s=0.75 s=1.0(LS)") 
